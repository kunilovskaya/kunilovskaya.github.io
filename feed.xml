<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://kunilovskaya.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://kunilovskaya.github.io/" rel="alternate" type="text/html" hreflang="en" /><updated>2025-08-28T14:06:48+00:00</updated><id>https://kunilovskaya.github.io/feed.xml</id><title type="html">Maria Kunilovskaya</title><subtitle>a contrastive linguist turned computational
</subtitle><entry><title type="html">teaching duties!</title><link href="https://kunilovskaya.github.io/blog/2025/teaching/" rel="alternate" type="text/html" title="teaching duties!" /><published>2025-05-14T00:00:00+00:00</published><updated>2025-05-14T00:00:00+00:00</updated><id>https://kunilovskaya.github.io/blog/2025/teaching</id><content type="html" xml:base="https://kunilovskaya.github.io/blog/2025/teaching/"><![CDATA[<h2 class="title">after several years of no teaching obligations</h2>

<p>I am firmly back at the other side of the classroom. This semester I am teaching my own seminar “Quality in Human and Machine Translation” 
(attended by 8 MA students with various backgrounds) and BA Abschlussarbeit Kolloquium (with Annemarie Verkerk).
Well, I am also a reasonably active student in the formal German classes for the 5th semester, learning at the challenging B2-C1 level.</p>

<p>I keep thinking that learning-teaching might truly be my thing. 
I enjoy the excitement and the challenge of the discovery and of telling an accessible story.
This might be psychologically more rewarding than lonely toiling on a research project which also returns disappointing results.</p>

<div class="row justify-content-sm-center">
    <div class="col-sm-4 mt-3 mt-md-0">
        <figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/as_audience-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/as_audience-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/as_audience-1400.webp" />
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/as_audience.jpg" title="wow, an engaging talk :-)" />

  </picture>

</figure>

    </div>
    <div class="col-sm-4 mt-3 mt-md-0">
        <figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/teamwork-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/teamwork-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/teamwork-1400.webp" />
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded" src="/assets/img/teamwork.jpg" title="brain-storming session" />

  </picture>

</figure>

    </div>
    <div class="col-sm-4 mt-3 mt-md-0">
        <figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/talking-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/talking-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/talking-1400.webp" />
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/talking.png" title="talking is so much fun" />

  </picture>

</figure>

    </div>
</div>]]></content><author><name></name></author><summary type="html"><![CDATA[back to the classroom]]></summary></entry><entry><title type="html">reviewing</title><link href="https://kunilovskaya.github.io/blog/2025/reviewing/" rel="alternate" type="text/html" title="reviewing" /><published>2025-05-10T00:00:00+00:00</published><updated>2025-05-10T00:00:00+00:00</updated><id>https://kunilovskaya.github.io/blog/2025/reviewing</id><content type="html" xml:base="https://kunilovskaya.github.io/blog/2025/reviewing/"><![CDATA[<h2 class="title">before the next batch of reviews</h2>

<p>A lot of my time and effort goes into reviewing. This is another voluntary community service that is important to me. 
I find reviewing enriching and enlightening. For me, it is a great opportunity to reflect on the developments in the field 
and to broaden my knowledge. I think I benefit from reading both great and not-so-great submissions – for various reasons.</p>

<p>The difficult thing is to find time to do the reading without being distracted by other competing tasks. The best setting for me is on the train or on a fight.
And I am very happy with my recent acquisition – Kindle Scribe – bought specifically for reviewing and note-taking at the conferences.</p>

<hr />

<p>I am proud to be named an outstanding reviewer by COLING-2025 organizers: <a href="/assets/img/who_is_outstanding_coling2025.jpg" target="blank">see a picture</a></p>

<hr />

<div class="row justify-content-sm-center">
    <div class="col-sm-4 mt-3 mt-md-0">
        <figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/review-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/review-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/review-1400.webp" />
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/review.jpg" title="" />

  </picture>

</figure>

    </div>
    <div class="col-sm-4 mt-3 mt-md-0">
        <figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/reviewer-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/reviewer-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/reviewer-1400.webp" />
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/reviewer.jpg" title="" />

  </picture>

</figure>

    </div>
</div>]]></content><author><name></name></author><summary type="html"><![CDATA[heartily recommend]]></summary></entry><entry><title type="html">jubilee parkrun</title><link href="https://kunilovskaya.github.io/blog/2022/parkrun0/" rel="alternate" type="text/html" title="jubilee parkrun" /><published>2022-06-03T00:00:00+00:00</published><updated>2022-06-03T00:00:00+00:00</updated><id>https://kunilovskaya.github.io/blog/2022/parkrun0</id><content type="html" xml:base="https://kunilovskaya.github.io/blog/2022/parkrun0/"><![CDATA[<h2 class="title">miracles of team spirit</h2>

<p>I have never liked running or the idea of it, except maybe dashes over a short distance.
The idea to carry on for more than 10 seconds has always been disturbing: it is painful, robotically numbing and uneventful.</p>

<p>When I see joggers, I wonder why they choose this self-torture. Their arguments fall into several categories: cerebral health reasons, addictive ecstasy-like experiences after the exercise and achievement/challenge motivations.</p>

<p>Quite unexpectedly, a casual lunch-time talk among non-runners in the office amounted to a resolution to give it a try. It was agreed to make it around the West Park, a one mile run. We allowed a month for practice: everybody was sure they would not make it. I honestly attempted the distance on my own a few days before the agreed date. I managed less than half, and it was hopeless: panting, red-veil effect, lack of motivation.</p>

<p>However, to respect the agreement, I did turn up at 9 a.m (sic!) on the Jubilee Day at the gazebo. My hope was that nobody would show up, and I would spend time watching trees and picking specimens for my herbarium.</p>

<p>When they did come, I failed to talk people out of attempting the intimidating immensity of the mile and into setting a reduced goal instead. We agreed that we were marking the starting level; setting a baseline against which to measure the progress, if we wanted to stay on the task.</p>

<p>Low baseline makes progress more visible and rewarding, we said, anticipating a quick and certain defeat.</p>

<p>But guess what? Everybody finished, even me! In 12 minutes. 
My only explanation is that it was the group effect. And it was not difficult for me, either. Not as difficult, as I expected or imagined. (A cynic might say that it is a case of low expectations inflating the outcomes).</p>

<p>It was a good long day after that, filled with quiet pastimes and pleasant mindless errands, none of which were on the TODO.</p>

<p>Now, we decided to have progress-recording runs every first Saturday each months. 
Give me more surprises!</p>

<div class="container">

	<div class="row">


		<div class="col">

		<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/before_jubilee_parkrun-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/before_jubilee_parkrun-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/before_jubilee_parkrun-1400.webp" />
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/before_jubilee_parkrun.jpg" title="milestone: one mile" />

  </picture>

</figure>


		</div>

		<div class="col">

		<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/yoga_stretching-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/yoga_stretching-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/yoga_stretching-1400.webp" />
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded" src="/assets/img/yoga_stretching.jpg" title="stretching is key, if you know how" />

  </picture>

</figure>


		</div>

		
		<div class="col">

		<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/running_per_se-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/running_per_se-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/running_per_se-1400.webp" />
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/running_per_se.jpg" title="and it is an early morning, too" />

  </picture>

</figure>


		</div>

	</div>

</div>]]></content><author><name></name></author><summary type="html"><![CDATA[first RGCL parkrun fails to set a low baseline]]></summary></entry><entry><title type="html">manual human translation quality annotation</title><link href="https://kunilovskaya.github.io/blog/2020/manual_annotation/" rel="alternate" type="text/html" title="manual human translation quality annotation" /><published>2020-11-20T17:39:00+00:00</published><updated>2020-11-20T17:39:00+00:00</updated><id>https://kunilovskaya.github.io/blog/2020/manual_annotation</id><content type="html" xml:base="https://kunilovskaya.github.io/blog/2020/manual_annotation/"><![CDATA[<p>I am engaged in a time- and effort-consuming, but insightful and potentially useful experiment in human translation quality annotation.
(It is a pity I cannot discuss it over lunch! No technical progress in Zoom, MS teams or Skype will be able to compensate for the opportunity to ruminate the research ideas over lunch and for the motivations of the office life. Let’s see whether blogging can be helpful.)</p>

<p>One of the problems I faced in my attempts to build a quality estimation system for human translation is the lack of a reliable and available gold standard. 
Which quality labels are most useful in a machine learning setting? But more importantly how do you get them?</p>

<h3 id="1-previous-attempts">1. Previous attempts</h3>
<p>I started my experiments with implementing two of the possible solutions:</p>
<ol>
  <li>‘Good’ vs. ‘Bad’. I used graded exam translations produced by professional translation programmes in several universities as well as data from a number of translation contests to build a quality annotated dataset, which featured binary labels (‘good’ vs. ‘bad’). We assumed that a binary classification into sharply opposed classes can be an easy task for a reasonably sophisticated learning setup. The improved dataset counted more than 400 texts of about 400 words each. Our best results on the proven translationese features reached accuracy of 67% (with the chance level as 55%). See details in Kunilovskaya, M., &amp; Lapshinova-Koltunski, E. (2019). Translationese Features as Indicators of Quality in English-Russian Human Translation. In Proceedings of the 2nd Workshop on Human-Informed Translation and Interpreting Technology (HiT-IT 2019) (pp. 47–56).
I also tried other approaches to text representation, ranging from tf-idf scaled character trigrams (and other bag-of-word representations) to get the accuracy of good-bad classification of 68% and bilingual vectors learnt on lemmatised corpora + Siamese architecture of bidirectional LSTM to feed the averaged vectors for the source and target texts. The latter experiment yielded the accuracy of 64%
Those efforts indicated that translation quality is either extremely difficult to learn or that I might have a problem with the labels in the dataset or the binary setup in general. The latter option sprang to mind after I verified the labels by re-annotating 20% of the data and removing a few texts that caused disagreements.</li>
  <li>Professional vs Student. Another way to approach the lack of reliable labels is to utilise the natural classes of texts, which can be assumed to reflect their quality (aka distant supervision). A typical case of such classes is (well-published) professional and learner translations. On the same set of morphosyntactic indicators of translationese we got the accuracy of 78% (see details in Kunilovskaya, M., &amp; Lapshinova-Koltunski, E. (2020). Lexicogrammatic Translationese across Two Targets and Competence Levels. Proceedings Of the 12th Conference on Language Resources and Evaluation (LREC 2020), 4102–4112). While this is an impressive achievement, given our trials with good-bad labels, we need to accept that professionalism is an adequate proxy for translation quality and that the student and professional collections do not differ much in terms of register. By assuming that professionalism is quality in this setting we effectively ignore the many factors associated with text production for students and professional (levels of responsibility, time constraints, levels of stress, extralinguistic motivations and situational conventions).</li>
</ol>

<h3 id="2-towards-a-continuous-sentence-level-quality-score">2. Towards a continuous sentence-level quality score</h3>

<p>The current annotation experiment aims to produce human judgments about translation quality in the Direct Assessment (DA) setting popular today in the field of machine translation (MT). It is going to be compared with the existing score based on error annotation to try and offer a triangulation of the human quality estimates.</p>

<p>(1) Annotator teams. The experiments involves 12 volunteers who are final year linguistics degree BA students in a Russian university. All participants have Russian L1 and English at B2 level; they are evaluating translations from English into Russian. They are assigned to two teams. Each team includes a group of three translators, i.e. students who have attended theoretical and practical courses in translation studies and three linguists, i.e. students who major in English teaching or contrastive linguistics. This profiles are supposed to give insights into the impact of (almost complete) translation education in the task of evaluating translation quality.</p>

<p>(2) Data. The student translations come from the error-annotated subset of Russian Learner Translator Corpus (www.rus-ltc.org) limited to general domain mass-media texts. Error annotation is used to produce a quality score to cross-validate the annotations in the current experiment. Getting the quality score from error annotations is again a matter of subjectively assigned weights, unfortunately. We decided to go with the following procedure: we calculate a translation’s negative score for language and content errors assigning the following weights to the attributes: ‘minor’: 10, ‘major’: 20, ‘critical’: 30, ‘kudo’: -10. To get the quality score for a text we subtract this score from a 100. To get one quality score for a target text we average the two scores for fluency and accuracy based on the number and weights for language and content errors. 
For annotation we offer texts that come from the extreme good-bad categories to provide sharp contrasts and clear quality distinctions in the data.</p>

<p>(3) Results of the calibration session. The experiments started in early October with a series of enlightening calibration sessions. Inspired by the reasoning in Graham et al (2013, 2017) and Deams et al (2013), where they suggest that fluency should be judged independently of adequacy/accuracy, we arranged for the annotators to evaluate translations in two conditions: as a text in the target language, independent of its source (fluency aspect of translation quality) and in the bilingual setting where the annotators are asked to compare the source segment and the target segment.
However, the results of the calibration session indicated that the participants struggle with separating the two aspects. In particular, even in the second round of annotation following an extended session analysing the oddities in the scores assigned in the first round, the inter-rater agreement was very low and the average annotated scores were miles away from the ones calculated from errors, annotated by a translation examiner in the same text. The discrepancies were particularly noticeable in the accuracy setting. 
This made me reconsider the experiment and respect the arguments in Callison-Burch et al. (2007) and Guzmán et al. (2019) who argue for syncretic quality annotation.
The third round of calibration in the setting which does not single out traditional quality aspects (fluency, accuracy) but asks the annotator to indicate whether a Russian segment is an adequate translation of the English segment, given the context, returns reasonable inter-rater agreement and the (expected) better match with the error-based scores, which have the role of gold standard in this annotation experiment.
Interestingly, based on the limited data from the calibration sessions, linguists tent to be more critical in their estimates, there is also less agreement between the raters with no prior translation education. On the other hand, translates tend to agree more and are more forgiving towards the work of their fellows in the profession.</p>

<p>(4) Task. The experiment is set up on the QuestionPro platform which importantly offers a slider question and unlimited number of surveys and participants for free, which suits our needs. While the annotation takes place on a sentence level, the task page contains a complete text to provide access to cohesion and textuality issues in translations. 
After the lessons learnt from several calibration sessions, we issued the first batch of 40 text pairs (922 sentence pairs) for annotation. The task is now formulated as “Read the source text. Use the slider to indicate how much you agree that the text in bold is an adequate translation of the original English sentence, given the context.”
We use a 100-point slider in accordance with the DA method of benchmarking translation quality in MT. It is supposed to alleviate the pressure to choose between 5 or 7 discreet bins in a traditional Likert scale setup. We also repeatedly urged the annotators to pay attention to the textual aspects of quality that can only be noticed in context, but have to be annotated on the sentence level (see Voita et al. 2019).
Naturally, I would be happy to get any feedback or ideas how to adjust the experiment setting to return the most reliable results.</p>

<p>Thanks for listening, anyway :-)</p>

<p>Dr. Maria Kunilovskaya</p>

<p>PhD researcher</p>

<p>Research Group in Computational Linguistics</p>

<p>University of Wolverhampton, UK</p>

<hr />

<p>Used to be published at the EMTTI student blog: http://rgcl.wlv.ac.uk/2020/11/23/phd-research-diaries-dr-maria-kunilovskaya/</p>]]></content><author><name></name></author><summary type="html"><![CDATA[setting up direct assessment for human translations]]></summary></entry></feed>